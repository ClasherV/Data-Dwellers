{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 14579,
     "status": "ok",
     "timestamp": 1758313976333,
     "user": {
      "displayName": "Vaibhav Raikwar",
      "userId": "06106236840848391083"
     },
     "user_tz": -330
    },
    "id": "xuZMUrVMN1tD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfOLYjJZVBXV"
   },
   "source": [
    "# Loading training Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1758313976337,
     "user": {
      "displayName": "Vaibhav Raikwar",
      "userId": "06106236840848391083"
     },
     "user_tz": -330
    },
    "id": "YQ3oDtCQU_oO"
   },
   "outputs": [],
   "source": [
    "def train_model():\n",
    "  train_attendance = pd.read_csv(\"TrainData/train_attendance_with_names.csv\")\n",
    "  train_fees = pd.read_csv(\"TrainData/train_fees.csv\")\n",
    "  train_scores = pd.read_csv(\"TrainData/train_scores.csv\")\n",
    "  train_labels = pd.read_csv(\"TrainData/train_labels.csv\")\n",
    "\n",
    "  train_data = train_attendance.merge(train_fees, on=\"student_id\").merge(train_scores, on=\"student_id\").merge(train_labels, on=\"student_id\")\n",
    "\n",
    "\n",
    "  num_features = [\n",
    "    \"attendance_percent\", \"avg_score\", \"num_failed_attempts\",\n",
    "    \"fees_paid_ratio\", \"assignments_submitted\", \"projects_completed\"\n",
    "]\n",
    "\n",
    "  target = \"dropout\"\n",
    "\n",
    "  x = train_data[num_features]\n",
    "  y = train_data[target]\n",
    "\n",
    "  scaler = StandardScaler()\n",
    "  x_scaled = scaler.fit_transform(x)\n",
    "\n",
    "  x_train, x_val, y_train, y_val = train_test_split(x_scaled, y, test_size=0.2, random_state=101, stratify=y)\n",
    "\n",
    "\n",
    "  smote = SMOTE(random_state=42)\n",
    "  x_train_resampled, y_train_resampled = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "\n",
    "  rf = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=101, class_weight=\"balanced\")\n",
    "  log = LogisticRegression(max_iter=1000,random_state=101, class_weight=\"balanced\")\n",
    "  gb = GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=5, random_state=101)\n",
    "  scale_pos_weight = (y_train.value_counts()[0]/y_train.value_counts()[1])\n",
    "  xgb=XGBClassifier(random_state=101, eval_metrics=\"logloss\", scale_pos_weight=scale_pos_weight, use_label_encoder=False)\n",
    "\n",
    "  ensemble = VotingClassifier(\n",
    "    estimators=[(\"rf\",rf),(\"log\",log),(\"gb\",gb),(\"xgb\",xgb)],\n",
    "    voting=\"soft\"\n",
    "  )\n",
    "\n",
    "  ensemble.fit(x_train_resampled, y_train_resampled)\n",
    "  y_pred = ensemble.predict(x_val)\n",
    "\n",
    "  y_proba = ensemble.predict_proba(x_val)[:, 1]\n",
    "  y_pred = (y_proba >= 0.4).astype(int)\n",
    "\n",
    "  print(\"\\n Ensemble Model Results:\")\n",
    "  print(\"Validation Accuracy : \",accuracy_score(y_val,y_pred))\n",
    "  print(\"Classification Report: \\n\",classification_report(y_val,y_pred))\n",
    "\n",
    "  joblib.dump(ensemble, \"dropout_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUqT-4dzKKn0"
   },
   "source": [
    "# Prediction on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1758313976348,
     "user": {
      "displayName": "Vaibhav Raikwar",
      "userId": "06106236840848391083"
     },
     "user_tz": -330
    },
    "id": "6s-MLvremiOI"
   },
   "outputs": [],
   "source": [
    "def predict_risk(model_path=\"dropout_model.pkl\",\n",
    "                 attendance_threshold=75,\n",
    "                 score_threshold=40,\n",
    "                 fee_overdue_threshold=0.7,\n",
    "                 max_exam_attempts=3,\n",
    "                 w_attendance=0.3,\n",
    "                 w_score=0.3,\n",
    "                 w_fee=0.2,\n",
    "                 w_attempts=0.2):\n",
    "  ensemble=joblib.load(model_path)\n",
    "\n",
    "  test_attendance = pd.read_csv(\"uploads/attendance.csv\")\n",
    "  test_fees = pd.read_csv(\"uploads/fees.csv\")\n",
    "  test_scores = pd.read_csv(\"uploads/assessment.csv\")\n",
    "  t1 = test_attendance.merge(test_fees, on=\"student_id\")\n",
    "  test_data = t1.merge(test_scores, on=\"student_id\")\n",
    "\n",
    "  x_test = test_data.drop(columns=[\"student_id\",\"student_name\",\"student_email\"])\n",
    "\n",
    "\n",
    "  numeric_features = [\"attendance_percent\", \"avg_score\", \"num_failed_attempts\", \"fees_paid_ratio\"]\n",
    "\n",
    "  # Scale only numeric features\n",
    "  scaler = StandardScaler()\n",
    "  x_test_scaled = x_test.copy()\n",
    "  x_test_scaled[numeric_features] = scaler.fit_transform(x_test[numeric_features])\n",
    "\n",
    "\n",
    "  y_proba = ensemble.predict_proba(x_test_scaled)[:, 1] * 100  # dropout probability (%)\n",
    "  y_pred = ensemble.predict(x_test_scaled)  # predicted labels (0=safe, 1=at risk)\n",
    "\n",
    "  # Add ML predictions directly into test_data\n",
    "  test_data[\"ML_dropout_probability\"] = y_proba\n",
    "  test_data[\"ML_prediction\"] = y_pred\n",
    "\n",
    "  # Normalize weights\n",
    "  total_w = w_attendance + w_score + w_fee + w_attempts\n",
    "  w_attendance, w_score, w_fee, w_attempts = (\n",
    "    w_attendance / total_w,\n",
    "    w_score / total_w,\n",
    "    w_fee / total_w,\n",
    "    w_attempts / total_w,\n",
    ")\n",
    "\n",
    "  # Rule-based risks\n",
    "  test_data[\"attendance_risk\"] = test_data[\"attendance_percent\"].apply(\n",
    "    lambda x: 1 if x < attendance_threshold else 0\n",
    ")\n",
    "  test_data[\"score_risk\"] = test_data[\"avg_score\"].apply(\n",
    "    lambda x: 1 if x < score_threshold else 0\n",
    ")\n",
    "  test_data[\"fee_risk\"] = test_data[\"fees_paid_ratio\"].apply(\n",
    "    lambda x: 1 if x < fee_overdue_threshold else 0\n",
    ")\n",
    "  test_data[\"attempts_risk\"] = test_data[\"num_failed_attempts\"].apply(\n",
    "    lambda x: 1 if x > max_exam_attempts else 0\n",
    ")\n",
    "\n",
    "  test_data[\"rule_dropout_probability\"] = (\n",
    "    test_data[\"attendance_risk\"] * w_attendance\n",
    "    + test_data[\"score_risk\"] * w_score\n",
    "    + test_data[\"fee_risk\"] * w_fee\n",
    "    + test_data[\"attempts_risk\"] * w_attempts\n",
    ") * 100\n",
    "\n",
    "  # Final blended probability\n",
    "  test_data[\"final_dropout_probability\"] = (\n",
    "    test_data[\"ML_dropout_probability\"] * 0.6\n",
    "    + test_data[\"rule_dropout_probability\"] * 0.4\n",
    ")\n",
    "\n",
    "  def classify_risk(prob):\n",
    "    if prob >= 70:\n",
    "        return \"High Risk\"\n",
    "    elif prob >= 40:\n",
    "        return \"Medium Risk\"\n",
    "    else:\n",
    "        return \"Low Risk\"\n",
    "\n",
    "  test_data[\"risk_level\"] = test_data[\"final_dropout_probability\"].apply(classify_risk)\n",
    "\n",
    "  # Filter only at-risk students\n",
    "  at_risk_students = test_data[test_data[\"risk_level\"] != \"Low Risk\"][\n",
    "    [\n",
    "        \"student_id\",\n",
    "        \"student_name\",\n",
    "        \"student_email\",\n",
    "        \"attendance_percent\",\n",
    "        \"avg_score\",\n",
    "        \"fees_paid_ratio\",\n",
    "        \"num_failed_attempts\",\n",
    "        \"ML_dropout_probability\",\n",
    "        \"rule_dropout_probability\",\n",
    "        \"final_dropout_probability\",\n",
    "        \"risk_level\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "  at_risk_students.to_csv(\"at_risk_students.csv\", index=False)\n",
    "  print(\"âœ… Final At-Risk Students Saved to at_risk_students.csv\")\n",
    "\n",
    "  # ðŸ”¹ Send file to Flask backend\n",
    "  url = \"http://127.0.0.1:5000/upload\"   # your Flask app endpoint\n",
    "  with open(\"at_risk_students.csv\", \"rb\") as f:\n",
    "    response = requests.post(url, files={\"file\": f})\n",
    "\n",
    "  return at_risk_students\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfAT4jzJd3KN"
   },
   "source": [
    "# Example run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7184,
     "status": "ok",
     "timestamp": 1758313983534,
     "user": {
      "displayName": "Vaibhav Raikwar",
      "userId": "06106236840848391083"
     },
     "user_tz": -330
    },
    "id": "BRUS2JEdd93T",
    "outputId": "bcc3be98-e64e-446b-a61e-a4d4531f751f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programming\\Python\\CPython Distribution\\Interpreter\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [02:29:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"eval_metrics\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Ensemble Model Results:\n",
      "Validation Accuracy :  0.845\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.67      0.76        73\n",
      "           1       0.83      0.94      0.89       127\n",
      "\n",
      "    accuracy                           0.84       200\n",
      "   macro avg       0.85      0.81      0.82       200\n",
      "weighted avg       0.85      0.84      0.84       200\n",
      "\n",
      "âœ… Final At-Risk Students Saved to at_risk_students.csv\n",
      "   student_id  student_name                student_email  attendance_percent  \\\n",
      "0           1    Pari Gupta  vaibhavraikwar505@gmail.com                  16   \n",
      "1           2   Rohan Verma   rohan.verma886@example.com                  29   \n",
      "2           3    Riya Verma    riya.verma577@example.com                  24   \n",
      "3           4   Rohan Reddy   rohan.reddy521@example.com                  20   \n",
      "4           5  Ishaan Gupta  ishaan.gupta751@example.com                  17   \n",
      "\n",
      "   avg_score  fees_paid_ratio  num_failed_attempts  ML_dropout_probability  \\\n",
      "0         61             0.19                    3               54.459432   \n",
      "1         93             0.28                    4               75.354183   \n",
      "2         80             0.19                    4               49.445461   \n",
      "3         27             0.08                    5               47.281404   \n",
      "4         86             0.14                    4               91.942027   \n",
      "\n",
      "   rule_dropout_probability  final_dropout_probability   risk_level  \n",
      "0                      70.0                  60.675659  Medium Risk  \n",
      "1                      70.0                  73.212510    High Risk  \n",
      "2                      70.0                  57.667277  Medium Risk  \n",
      "3                     100.0                  68.368842  Medium Risk  \n",
      "4                      70.0                  83.165216    High Risk  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programming\\Python\\CPython Distribution\\Interpreter\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "e:\\Programming\\Python\\CPython Distribution\\Interpreter\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "e:\\Programming\\Python\\CPython Distribution\\Interpreter\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "e:\\Programming\\Python\\CPython Distribution\\Interpreter\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "e:\\Programming\\Python\\CPython Distribution\\Interpreter\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "e:\\Programming\\Python\\CPython Distribution\\Interpreter\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Train model once (only when needed)\n",
    "    train_model()\n",
    "\n",
    "    # Later: load and predict dynamically\n",
    "    results = predict_risk(\n",
    "        attendance_threshold=70,\n",
    "        score_threshold=45,\n",
    "        fee_overdue_threshold=0.6,\n",
    "        max_exam_attempts=2,\n",
    "        w_attendance=0.4,\n",
    "        w_score=0.3,\n",
    "        w_fee=0.2,\n",
    "        w_attempts=0.1\n",
    "    )\n",
    "\n",
    "    print(results.head())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1pkCDyf-xuyl7mkHqQyH8vq5KyxTVKd62",
     "timestamp": 1758314003480
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
